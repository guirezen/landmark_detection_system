{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcc8df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Notebook 3: An√°lise e Compara√ß√£o dos Resultados\\n\",\n",
    "    \"\\n\",\n",
    "    \"Este notebook foca na an√°lise quantitativa e compara√ß√£o dos resultados obtidos pelos m√©todos Geom√©trico e de Machine Learning. Ele utiliza as fun√ß√µes do m√≥dulo `metrics.py` para calcular erros e taxas de detec√ß√£o.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Pr√©-requisitos:**\\n\",\n",
    "    \"1. Resultados da detec√ß√£o (arquivos JSON) gerados para ambos os m√©todos\\n\",\n",
    "    \"2. Arquivos JSON contendo as coordenadas ground truth (GT) correspondentes\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Objetivos:**\\n\",\n",
    "    \"1. Carregar os resultados previstos e os dados ground truth\\n\",\n",
    "    \"2. Calcular m√©tricas (Erro por landmark, MDE, Taxa de Detec√ß√£o) para cada m√©todo\\n\",\n",
    "    \"3. Gerar DataFrames com os resultados detalhados e agregados\\n\",\n",
    "    \"4. Criar visualiza√ß√µes comparativas (boxplots, gr√°ficos de barras)\\n\",\n",
    "    \"5. Analisar a complexidade computacional\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configura√ß√µes Iniciais e Imports\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import logging\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import trimesh\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Adicionar o diret√≥rio raiz do projeto ao path\\n\",\n",
    "    \"module_path = os.path.abspath(os.path.join(\\\"..\\\"))\\n\",\n",
    "    \"if module_path not in sys.path:\\n\",\n",
    "    \"    sys.path.append(module_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.utils.metrics import run_evaluation_on_dataset, load_landmarks_from_json\\n\",\n",
    "    \"from src.utils.helpers import setup_logging, list_stl_files, save_landmarks_to_json\\n\",\n",
    "    \"from src.core.landmarks import LANDMARK_NAMES\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configurar logging\\n\",\n",
    "    \"setup_logging(log_level=logging.INFO)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configurar estilo dos gr√°ficos\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Diret√≥rio de trabalho: {os.getcwd()}\\\")\\n\",\n",
    "    \"print(f\\\"Path do m√≥dulo: {module_path}\\\")\\n\",\n",
    "    \"print(f\\\"Landmarks definidos: {len(LANDMARK_NAMES)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configurar diret√≥rios\\n\",\n",
    "    \"BASE_DIR = module_path\\n\",\n",
    "    \"RESULTS_DIR = os.path.join(BASE_DIR, \\\"results\\\")\\n\",\n",
    "    \"RESULTS_GEOM_DIR = os.path.join(RESULTS_DIR, \\\"geometric\\\") \\n\",\n",
    "    \"RESULTS_ML_DIR = os.path.join(RESULTS_DIR, \\\"ml\\\")\\n\",\n",
    "    \"GROUND_TRUTH_DIR = os.path.join(BASE_DIR, \\\"data\\\", \\\"ground_truth\\\")\\n\",\n",
    "    \"DATA_DIR = os.path.join(BASE_DIR, \\\"data\\\", \\\"skulls\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Criar diret√≥rios se n√£o existirem\\n\",\n",
    "    \"for directory in [RESULTS_GEOM_DIR, RESULTS_ML_DIR, GROUND_TRUTH_DIR, DATA_DIR]:\\n\",\n",
    "    \"    os.makedirs(directory, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Diret√≥rios configurados:\\\")\\n\",\n",
    "    \"print(f\\\"  Resultados gerais: {RESULTS_DIR}\\\")\\n\",\n",
    "    \"print(f\\\"  Resultados geom√©tricos: {RESULTS_GEOM_DIR}\\\")\\n\",\n",
    "    \"print(f\\\"  Resultados ML: {RESULTS_ML_DIR}\\\")\\n\",\n",
    "    \"print(f\\\"  Ground truth: {GROUND_TRUTH_DIR}\\\")\\n\",\n",
    "    \"print(f\\\"  Dados originais: {DATA_DIR}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Criar dados dummy para demonstra√ß√£o\\n\",\n",
    "    \"# Em um cen√°rio real, estes dados viriam de execu√ß√µes do main.py\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"=== Criando Dados Dummy para Demonstra√ß√£o ===\\\")\\n\",\n",
    "    \"print(\\\"‚ö†Ô∏è  Em um cen√°rio real, estes dados seriam gerados pelo main.py\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"DUMMY_FILE_IDS = [\\\"dummy_A\\\", \\\"dummy_B\\\", \\\"dummy_C\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for file_id in DUMMY_FILE_IDS:\\n\",\n",
    "    \"    # 1. Criar arquivo STL dummy (se n√£o existir)\\n\",\n",
    "    \"    dummy_stl_path = os.path.join(DATA_DIR, f\\\"{file_id}.stl\\\")\\n\",\n",
    "    \"    if not os.path.exists(dummy_stl_path):\\n\",\n",
    "    \"        mesh_dummy = trimesh.primitives.Sphere(radius=50 + np.random.randint(10))\\n\",\n",
    "    \"        mesh_dummy.export(dummy_stl_path)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    # 2. Criar Ground Truth dummy com coordenadas realistas\\n\",\n",
    "    \"    gt_path = os.path.join(GROUND_TRUTH_DIR, f\\\"{file_id}_landmarks_gt.json\\\")\\n\",\n",
    "    \"    if not os.path.exists(gt_path):\\n\",\n",
    "    \"        # Gerar coordenadas GT realistas baseadas em anatomia\\n\",\n",
    "    \"        base_coords = {\\n\",\n",
    "    \"            \\\"Glabela\\\": [0, 50, 50],\\n\",\n",
    "    \"            \\\"Nasion\\\": [0, 45, 40], \\n\",\n",
    "    \"            \\\"Bregma\\\": [0, 0, 100],\\n\",\n",
    "    \"            \\\"Opisthocranion\\\": [0, -50, 50],\\n\",\n",
    "    \"            \\\"Euryon_Esquerdo\\\": [-50, 0, 50],\\n\",\n",
    "    \"            \\\"Euryon_Direito\\\": [50, 0, 50],\\n\",\n",
    "    \"            \\\"Vertex\\\": [0, 5, 100],\\n\",\n",
    "    \"            \\\"Inion\\\": [0, -45, 35]\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Adicionar varia√ß√£o individual\\n\",\n",
    "    \"        gt_data = {}\\n\",\n",
    "    \"        for name, base_coord in base_coords.items():\\n\",\n",
    "    \"            # Adicionar varia√ß√£o de ¬±5mm em cada eixo\\n\",\n",
    "    \"            variation = (np.random.rand(3) - 0.5) * 10\\n\",\n",
    "    \"            gt_data[name] = (np.array(base_coord) + variation).tolist()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Simular alguns landmarks ausentes no GT\\n\",\n",
    "    \"        if file_id == \\\"dummy_C\\\":\\n\",\n",
    "    \"            gt_data[\\\"Vertex\\\"] = None\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        with open(gt_path, \\\"w\\\") as f:\\n\",\n",
    "    \"            json.dump(gt_data, f, indent=4)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 3. Criar resultados geom√©tricos dummy (com erro simulado)\\n\",\n",
    "    \"    geom_pred_path = os.path.join(RESULTS_GEOM_DIR, f\\\"{file_id}_landmarks.json\\\")\\n\",\n",
    "    \"    if not os.path.exists(geom_pred_path):\\n\",\n",
    "    \"        gt_data = load_landmarks_from_json(gt_path)\\n\",\n",
    "    \"        if gt_data:\\n\",\n",
    "    \"            geom_pred = {}\\n\",\n",
    "    \"            for name, gt_coord in gt_data.items():\\n\",\n",
    "    \"                if gt_coord is not None and np.random.rand() > 0.15:  # 85% detec√ß√£o\\n\",\n",
    "    \"                    # Erro simulado: ¬±3mm com vi√©s\\n\",\n",
    "    \"                    error = (np.random.rand(3) - 0.5) * 6\\n\",\n",
    "    \"                    geom_pred[name] = (np.array(gt_coord) + error).tolist()\\n\",\n",
    "    \"                else:\\n\",\n",
    "    \"                    geom_pred[name] = None\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            with open(geom_pred_path, \\\"w\\\") as f:\\n\",\n",
    "    \"                json.dump(geom_pred, f, indent=4)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 4. Criar resultados ML dummy (erro menor, melhor taxa)\\n\",\n",
    "    \"    ml_pred_path = os.path.join(RESULTS_ML_DIR, f\\\"{file_id}_landmarks.json\\\")\\n\",\n",
    "    \"    if not os.path.exists(ml_pred_path):\\n\",\n",
    "    \"        gt_data = load_landmarks_from_json(gt_path)\\n\",\n",
    "    \"        if gt_data:\\n\",\n",
    "    \"            ml_pred = {}\\n\",\n",
    "    \"            for name, gt_coord in gt_data.items():\\n\",\n",
    "    \"                if gt_coord is not None and np.random.rand() > 0.05:  # 95% detec√ß√£o\\n\",\n",
    "    \"                    # Erro menor: ¬±1.5mm\\n\",\n",
    "    \"                    error = (np.random.rand(3) - 0.5) * 3\\n\",\n",
    "    \"                    ml_pred[name] = (np.array(gt_coord) + error).tolist()\\n\",\n",
    "    \"                else:\\n\",\n",
    "    \"                    ml_pred[name] = None\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            with open(ml_pred_path, \\\"w\\\") as f:\\n\",\n",
    "    \"                json.dump(ml_pred, f, indent=4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"‚úÖ Dados dummy criados para {len(DUMMY_FILE_IDS)} arquivos\\\")\\n\",\n",
    "    \"print(f\\\"   Ground truth: {len(DUMMY_FILE_IDS)} arquivos\\\")\\n\",\n",
    "    \"print(f\\\"   Resultados geom√©tricos: {len(list(Path(RESULTS_GEOM_DIR).glob('*.json')))} arquivos\\\")\\n\",\n",
    "    \"print(f\\\"   Resultados ML: {len(list(Path(RESULTS_ML_DIR).glob('*.json')))} arquivos\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Executar Avalia√ß√£o para Cada M√©todo\\n\",\n",
    "    \"\\n\",\n",
    "    \"Utilizamos a fun√ß√£o `run_evaluation_on_dataset` para processar os arquivos de resultado e ground truth, gerando DataFrames com as m√©tricas.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== Executando Avalia√ß√£o dos M√©todos ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Avalia√ß√£o do M√©todo Geom√©trico\\n\",\n",
    "    \"print(\\\"\\\\nüîç Avaliando M√©todo Geom√©trico...\\\")\\n\",\n",
    "    \"results_geom_df, summary_geom_df = run_evaluation_on_dataset(\\n\",\n",
    "    \"    results_dir=RESULTS_GEOM_DIR, \\n\",\n",
    "    \"    ground_truth_dir=GROUND_TRUTH_DIR, \\n\",\n",
    "    \"    method_name=\\\"Geometric\\\"\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not results_geom_df.empty:\\n\",\n",
    "    \"    print(f\\\"‚úÖ Avalia√ß√£o geom√©trica conclu√≠da: {len(results_geom_df)} registros\\\")\\n\",\n",
    "    \"    overall_geom_rate = results_geom_df[\\\"Detected\\\"].mean() * 100\\n\",\n",
    "    \"    overall_geom_error = results_geom_df[\\\"Error\\\"].mean()\\n\",\n",
    "    \"    print(f\\\"   Taxa de detec√ß√£o: {overall_geom_rate:.1f}%\\\")\\n\",\n",
    "    \"    print(f\\\"   Erro m√©dio: {overall_geom_error:.3f} mm\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Avalia√ß√£o geom√©trica falhou\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Avalia√ß√£o do M√©todo ML\\n\",\n",
    "    \"print(\\\"\\\\nüîç Avaliando M√©todo Machine Learning...\\\")\\n\",\n",
    "    \"results_ml_df, summary_ml_df = run_evaluation_on_dataset(\\n\",\n",
    "    \"    results_dir=RESULTS_ML_DIR, \\n\",\n",
    "    \"    ground_truth_dir=GROUND_TRUTH_DIR, \\n\",\n",
    "    \"    method_name=\\\"ML\\\"\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not results_ml_df.empty:\\n\",\n",
    "    \"    print(f\\\"‚úÖ Avalia√ß√£o ML conclu√≠da: {len(results_ml_df)} registros\\\")\\n\",\n",
    "    \"    overall_ml_rate = results_ml_df[\\\"Detected\\\"].mean() * 100\\n\",\n",
    "    \"    overall_ml_error = results_ml_df[\\\"Error\\\"].mean()\\n\",\n",
    "    \"    print(f\\\"   Taxa de detec√ß√£o: {overall_ml_rate:.1f}%\\\")\\n\",\n",
    "    \"    print(f\\\"   Erro m√©dio: {overall_ml_error:.3f} mm\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Avalia√ß√£o ML falhou\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Combinar resultados para an√°lise comparativa\\n\",\n",
    "    \"results_combined_df = pd.DataFrame()\\n\",\n",
    "    \"summary_combined_df = pd.DataFrame()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not results_geom_df.empty and not results_ml_df.empty:\\n\",\n",
    "    \"    results_combined_df = pd.concat([results_geom_df, results_ml_df], ignore_index=True)\\n\",\n",
    "    \"    summary_combined_df = pd.concat([summary_geom_df, summary_ml_df], ignore_index=True)\\n\",\n",
    "    \"    print(f\\\"\\\\nüìä Datasets combinados criados:\\\")\\n\",\n",
    "    \"    print(f\\\"   Resultados detalhados: {len(results_combined_df)} registros\\\")\\n\",\n",
    "    \"    print(f\\\"   Resumo por landmark: {len(summary_combined_df)} registros\\\")\\n\",\n",
    "    \"elif not results_geom_df.empty:\\n\",\n",
    "    \"    results_combined_df = results_geom_df\\n\",\n",
    "    \"    summary_combined_df = summary_geom_df\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è  Apenas resultados geom√©tricos dispon√≠veis\\\")\\n\",\n",
    "    \"elif not results_ml_df.empty:\\n\",\n",
    "    \"    results_combined_df = results_ml_df\\n\",\n",
    "    \"    summary_combined_df = summary_ml_df\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è  Apenas resultados ML dispon√≠veis\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Nenhum resultado v√°lido para an√°lise\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Salvar datasets combinados\\n\",\n",
    "    \"if not results_combined_df.empty:\\n\",\n",
    "    \"    results_csv = os.path.join(RESULTS_DIR, \\\"evaluation_combined_detailed.csv\\\")\\n\",\n",
    "    \"    summary_csv = os.path.join(RESULTS_DIR, \\\"evaluation_combined_summary.csv\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results_combined_df.to_csv(results_csv, index=False)\\n\",\n",
    "    \"    summary_combined_df.to_csv(summary_csv, index=False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüíæ Resultados salvos:\\\")\\n\",\n",
    "    \"    print(f\\\"   Detalhados: {results_csv}\\\")\\n\",\n",
    "    \"    print(f\\\"   Resumo: {summary_csv}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Exibir resumo dos resultados\\n\",\n",
    "    \"if not results_combined_df.empty:\\n\",\n",
    "    \"    print(\\\"=== Resumo dos Resultados Detalhados ===\\\")\\n\",\n",
    "    \"    print(results_combined_df.head(10).round(3))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"if not summary_combined_df.empty:\\n\",\n",
    "    \"    print(\\\"\\\\n=== Resumo Agregado por Landmark ===\\\")\\n\",\n",
    "    \"    # Formatar colunas num√©ricas\\n\",\n",
    "    \"    display_summary = summary_combined_df.copy()\\n\",\n",
    "    \"    numeric_cols = ['MeanError', 'StdError', 'MedianError', 'MinError', 'MaxError', 'DetectionRate']\\n\",\n",
    "    \"    for col in numeric_cols:\\n\",\n",
    "    \"        if col in display_summary.columns:\\n\",\n",
    "    \"            if col == 'DetectionRate':\\n\",\n",
    "    \"                display_summary[col] = display_summary[col].round(1).astype(str) + '%'\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                display_summary[col] = display_summary[col].round(3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(display_summary[['Landmark', 'MeanError', 'DetectionRate', 'NumDetected', 'NumGT']].head(10))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Visualiza√ß√£o Comparativa das M√©tricas\\n\",\n",
    "    \"\\n\",\n",
    "    \"Criamos gr√°ficos para visualizar e comparar a performance dos dois m√©todos.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== Gerando Visualiza√ß√µes Comparativas ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not results_combined_df.empty:\\n\",\n",
    "    \"    # Preparar dados para visualiza√ß√£o (remover NaN para os gr√°ficos)\\n\",\n",
    "    \"    plot_data = results_combined_df.dropna(subset=['Error'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if len(plot_data) > 0:\\n\",\n",
    "    \"        # Configurar subplots\\n\",\n",
    "    \"        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\\n\",\n",
    "    \"        fig.suptitle('An√°lise Comparativa dos M√©todos de Detec√ß√£o', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Gr√°fico 1: Boxplot do Erro por M√©todo\\n\",\n",
    "    \"        ax1 = axes[0, 0]\\n\",\n",
    "    \"        sns.boxplot(data=plot_data, x=\\\"Method\\\", y=\\\"Error\\\", ax=ax1)\\n\",\n",
    "    \"        ax1.set_title(\\\"Distribui√ß√£o de Erros por M√©todo\\\")\\n\",\n",
    "    \"        ax1.set_ylabel(\\\"Erro de Detec√ß√£o (mm)\\\")\\n\",\n",
    "    \"        ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Gr√°fico 2: Boxplot do Erro por Landmark\\n\",\n",
    "    \"        ax2 = axes[0, 1]\\n\",\n",
    "    \"        # Selecionar apenas landmarks com dados suficientes\\n\",\n",
    "    \"        landmark_counts = plot_data['Landmark'].value_counts()\\n\",\n",
    "    \"        popular_landmarks = landmark_counts[landmark_counts >= 2].index[:6]  # Top 6\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if len(popular_landmarks) > 0:\\n\",\n",
    "    \"            landmark_data = plot_data[plot_data['Landmark'].isin(popular_landmarks)]\\n\",\n",
    "    \"            sns.boxplot(data=landmark_data, x=\\\"Landmark\\\", y=\\\"Error\\\", ax=ax2)\\n\",\n",
    "    \"            ax2.set_title(\\\"Distribui√ß√£o de Erros por Landmark\\\")\\n\",\n",
    "    \"            ax2.set_ylabel(\\\"Erro de Detec√ß√£o (mm)\\\")\\n\",\n",
    "    \"            ax2.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"            ax2.grid(True, alpha=0.3)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            ax2.text(0.5, 0.5, 'Dados insuficientes\\\\npara landmarks', \\n\",\n",
    "    \"                    ha='center', va='center', transform=ax2.transAxes)\\n\",\n",
    "    \"            ax2.set_title(\\\"Distribui√ß√£o por Landmark\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Gr√°fico 3: Taxa de Detec√ß√£o por M√©todo\\n\",\n",
    "    \"        ax3 = axes[1, 0]\\n\",\n",
    "    \"        if not summary_combined_df.empty:\\n\",\n",
    "    \"            method_summary = summary_combined_df.groupby('Method')['DetectionRate'].mean().reset_index()\\n\",\n",
    "    \"            method_summary['Method'] = method_summary['Method'].fillna('Unknown')\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            bars = sns.barplot(data=method_summary, x=\\\"Method\\\", y=\\\"DetectionRate\\\", ax=ax3)\\n\",\n",
    "    \"            ax3.set_title(\\\"Taxa de Detec√ß√£o M√©dia por M√©todo\\\")\\n\",\n",
    "    \"            ax3.set_ylabel(\\\"Taxa de Detec√ß√£o (%)\\\")\\n\",\n",
    "    \"            ax3.set_ylim(0, 105)\\n\",\n",
    "    \"            ax3.grid(True, alpha=0.3)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Adicionar valores nas barras\\n\",\n",
    "    \"            for i, bar in enumerate(bars.patches):\\n\",\n",
    "    \"                height = bar.get_height()\\n\",\n",
    "    \"                if not np.isnan(height):\\n\",\n",
    "    \"                    ax3.text(bar.get_x() + bar.get_width()/2., height + 1,\\n\",\n",
    "    \"                           f'{height:.1f}%', ha='center', va='bottom')\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            ax3.text(0.5, 0.5, 'Dados de resumo\\\\nn√£o dispon√≠veis', \\n\",\n",
    "    \"                    ha='center', va='center', transform=ax3.transAxes)\\n\",\n",
    "    \"            ax3.set_title(\\\"Taxa de Detec√ß√£o por M√©todo\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Gr√°fico 4: Scatter Error vs Landmark para ambos m√©todos\\n\",\n",
    "    \"        ax4 = axes[1, 1]\\n\",\n",
    "    \"        if 'Method' in plot_data.columns and len(plot_data['Method'].unique()) > 1:\\n\",\n",
    "    \"            for method in plot_data['Method'].unique():\\n\",\n",
    "    \"                method_data = plot_data[plot_data['Method'] == method]\\n\",\n",
    "    \"                ax4.scatter(range(len(method_data)), method_data['Error'], \\n\",\n",
    "    \"                          label=method, alpha=0.6, s=30)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            ax4.set_title(\\\"Erro de Detec√ß√£o por Amostra\\\")\\n\",\n",
    "    \"            ax4.set_xlabel(\\\"√çndice da Amostra\\\")\\n\",\n",
    "    \"            ax4.set_ylabel(\\\"Erro (mm)\\\")\\n\",\n",
    "    \"            ax4.legend()\\n\",\n",
    "    \"            ax4.grid(True, alpha=0.3)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            ax4.scatter(range(len(plot_data)), plot_data['Error'], alpha=0.6)\\n\",\n",
    "    \"            ax4.set_title(\\\"Erro de Detec√ß√£o por Amostra\\\")\\n\",\n",
    "    \"            ax4.set_xlabel(\\\"√çndice da Amostra\\\")\\n\",\n",
    "    \"            ax4.set_ylabel(\\\"Erro (mm)\\\")\\n\",\n",
    "    \"            ax4.grid(True, alpha=0.3)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Salvar gr√°fico\\n\",\n",
    "    \"        comparison_plot_path = os.path.join(RESULTS_DIR, \\\"comparison_analysis.png\\\")\\n\",\n",
    "    \"        plt.savefig(comparison_plot_path, dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"        print(f\\\"‚úÖ Gr√°fico de an√°lise comparativa salvo em: {comparison_plot_path}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"‚ùå N√£o h√° dados v√°lidos (sem NaN) para gerar gr√°ficos\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Dados combinados n√£o dispon√≠veis para visualiza√ß√£o\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. An√°lise Estat√≠stica Detalhada\\n\",\n",
    "    \"\\n\",\n",
    "    \"Realizamos uma an√°lise estat√≠stica mais aprofundada dos resultados.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== An√°lise Estat√≠stica Detalhada ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not results_combined_df.empty:\\n\",\n",
    "    \"    # Estat√≠sticas gerais por m√©todo\\n\",\n",
    "    \"    print(\\\"\\\\nüìä Estat√≠sticas Gerais por M√©todo:\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for method in results_combined_df['Method'].unique():\\n\",\n",
    "    \"        method_data = results_combined_df[results_combined_df['Method'] == method]\\n\",\n",
    "    \"        valid_errors = method_data['Error'].dropna()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if len(valid_errors) > 0:\\n\",\n",
    "    \"            print(f\\\"\\\\n{method}:\\\")\\n\",\n",
    "    \"            print(f\\\"  Total de detec√ß√µes: {len(method_data)}\\\")\\n\",\n",
    "    \"            print(f\\\"  Detec√ß√µes v√°lidas: {len(valid_errors)} ({len(valid_errors)/len(method_data)*100:.1f}%)\\\")\\n\",\n",
    "    \"            print(f\\\"  Erro m√©dio: {valid_errors.mean():.3f} ¬± {valid_errors.std():.3f} mm\\\")\\n\",\n",
    "    \"            print(f\\\"  Erro mediano: {valid_errors.median():.3f} mm\\\")\\n\",\n",
    "    \"            print(f\\\"  Erro m√≠nimo: {valid_errors.min():.3f} mm\\\")\\n\",\n",
    "    \"            print(f\\\"  Erro m√°ximo: {valid_errors.max():.3f} mm\\\")\\n\",\n",
    "    \"            print(f\\\"  Percentil 95: {valid_errors.quantile(0.95):.3f} mm\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"\\\\n{method}: Sem erros v√°lidos para an√°lise\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # An√°lise por landmark\\n\",\n",
    "    \"    if not summary_combined_df.empty:\\n\",\n",
    "    \"        print(\\\"\\\\nüéØ Top Landmarks por Taxa de Detec√ß√£o:\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Agrupar por landmark (m√©dia entre m√©todos)\\n\",\n",
    "    \"        landmark_avg = summary_combined_df.groupby('Landmark').agg({\\n\",\n",
    "    \"            'DetectionRate': 'mean',\\n\",\n",
    "    \"            'MeanError': 'mean',\\n\",\n",
    "    \"            'NumDetected': 'sum',\\n\",\n",
    "    \"            'NumGT': 'sum'\\n\",\n",
    "    \"        }).round(3)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Ordenar por taxa de detec√ß√£o\\n\",\n",
    "    \"        landmark_avg_sorted = landmark_avg.sort_values('DetectionRate', ascending=False)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(landmark_avg_sorted.head(8))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Landmarks mais desafiadores\\n\",\n",
    "    \"        print(\\\"\\\\n‚ö†Ô∏è  Landmarks Mais Desafiadores (baixa taxa de detec√ß√£o):\\\")\\n\",\n",
    "    \"        challenging = landmark_avg_sorted.tail(3)\\n\",\n",
    "    \"        for landmark, data in challenging.iterrows():\\n\",\n",
    "    \"            print(f\\\"  {landmark}: {data['DetectionRate']:.1f}% detec√ß√£o, erro {data['MeanError']:.3f}mm\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Landmarks mais precisos\\n\",\n",
    "    \"        print(\\\"\\\\n‚úÖ Landmarks Mais Precisos (menor erro):\\\")\\n\",\n",
    "    \"        precise = landmark_avg.dropna(subset=['MeanError']).sort_values('MeanError').head(3)\\n\",\n",
    "    \"        for landmark, data in precise.iterrows():\\n\",\n",
    "    \"            print(f\\\"  {landmark}: {data['MeanError']:.3f}mm erro, {data['DetectionRate']:.1f}% detec√ß√£o\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Compara√ß√£o estat√≠stica entre m√©todos (se ambos dispon√≠veis)\\n\",\n",
    "    \"    methods = results_combined_df['Method'].unique()\\n\",\n",
    "    \"    if len(methods) >= 2:\\n\",\n",
    "    \"        print(\\\"\\\\nüîç Compara√ß√£o Estat√≠stica entre M√©todos:\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        method1_errors = results_combined_df[results_combined_df['Method'] == methods[0]]['Error'].dropna()\\n\",\n",
    "    \"        method2_errors = results_combined_df[results_combined_df['Method'] == methods[1]]['Error'].dropna()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if len(method1_errors) > 0 and len(method2_errors) > 0:\\n\",\n",
    "    \"            # Teste t (assumindo normalidade)\\n\",\n",
    "    \"            from scipy import stats\\n\",\n",
    "    \"            t_stat, p_value = stats.ttest_ind(method1_errors, method2_errors)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            print(f\\\"  Diferen√ßa de m√©dias: {method1_errors.mean() - method2_errors.mean():.3f} mm\\\")\\n\",\n",
    "    \"            print(f\\\"  Teste t: t={t_stat:.3f}, p={p_value:.4f}\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if p_value < 0.05:\\n\",\n",
    "    \"                better_method = methods[0] if method1_errors.mean() < method2_errors.mean() else methods[1]\\n\",\n",
    "    \"                print(f\\\"  ‚úÖ {better_method} √© significativamente melhor (p < 0.05)\\\")\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                print(f\\\"  ‚öñÔ∏è  N√£o h√° diferen√ßa significativa entre os m√©todos (p >= 0.05)\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"  Dados insuficientes para compara√ß√£o estat√≠stica\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Dados n√£o dispon√≠veis para an√°lise estat√≠stica\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Relat√≥rio de Performance por Landmark\\n\",\n",
    "    \"\\n\",\n",
    "    \"Geramos um relat√≥rio detalhado da performance de cada landmark.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== Relat√≥rio de Performance por Landmark ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not summary_combined_df.empty:\\n\",\n",
    "    \"    # Criar relat√≥rio por landmark\\n\",\n",
    "    \"    landmark_report = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for landmark in LANDMARK_NAMES:\\n\",\n",
    "    \"        landmark_data = summary_combined_df[summary_combined_df['Landmark'] == landmark]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if not landmark_data.empty:\\n\",\n",
    "    \"            # Calcular m√©tricas m√©dias entre m√©todos\\n\",\n",
    "    \"            avg_detection_rate = landmark_data['DetectionRate'].mean()\\n\",\n",
    "    \"            avg_error = landmark_data['MeanError'].mean()\\n\",\n",
    "    \"            total_detected = landmark_data['NumDetected'].sum()\\n\",\n",
    "    \"            total_gt = landmark_data['NumGT'].sum()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Classificar dificuldade\\n\",\n",
    "    \"            if avg_detection_rate >= 90:\\n\",\n",
    "    \"                difficulty = \\\"F√°cil üòä\\\"\\n\",\n",
    "    \"            elif avg_detection_rate >= 70:\\n\",\n",
    "    \"                difficulty = \\\"Moderado üòê\\\"\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                difficulty = \\\"Dif√≠cil üòì\\\"\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Classificar precis√£o\\n\",\n",
    "    \"            if not np.isnan(avg_error):\\n\",\n",
    "    \"                if avg_error <= 2.0:\\n\",\n",
    "    \"                    precision = \\\"Alta ‚úÖ\\\"\\n\",\n",
    "    \"                elif avg_error <= 5.0:\\n\",\n",
    "    \"                    precision = \\\"M√©dia ‚ö†Ô∏è\\\"\\n\",\n",
    "    \"                else:\\n\",\n",
    "    \"                    precision = \\\"Baixa ‚ùå\\\"\\n\",\n",
    "    \"                error_str = f\\\"{avg_error:.2f}mm\\\"\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                precision = \\\"N/A\\\"\\n\",\n",
    "    \"                error_str = \\\"N/A\\\"\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            landmark_report.append({\\n\",\n",
    "    \"                'Landmark': landmark,\\n\",\n",
    "    \"                'Taxa_Detec√ß√£o': f\\\"{avg_detection_rate:.1f}%\\\",\\n\",\n",
    "    \"                'Erro_M√©dio': error_str,\\n\",\n",
    "    \"                'Dificuldade': difficulty,\\n\",\n",
    "    \"                'Precis√£o': precision,\\n\",\n",
    "    \"                'Detec√ß√µes': f\\\"{total_detected}/{total_gt}\\\"\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Criar DataFrame do relat√≥rio\\n\",\n",
    "    \"    if landmark_report:\\n\",\n",
    "    \"        report_df = pd.DataFrame(landmark_report)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"\\\\nüìã Relat√≥rio Resumido por Landmark:\\\")\\n\",\n",
    "    \"        print(report_df.to_string(index=False))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Salvar relat√≥rio\\n\",\n",
    "    \"        report_path = os.path.join(RESULTS_DIR, \\\"landmark_performance_report.csv\\\")\\n\",\n",
    "    \"        report_df.to_csv(report_path, index=False)\\n\",\n",
    "    \"        print(f\\\"\\\\nüíæ Relat√≥rio salvo em: {report_path}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Estat√≠sticas do relat√≥rio\\n\",\n",
    "    \"        easy_count = sum(1 for item in landmark_report if \\\"F√°cil\\\" in item['Dificuldade'])\\n\",\n",
    "    \"        moderate_count = sum(1 for item in landmark_report if \\\"Moderado\\\" in item['Dificuldade'])\\n\",\n",
    "    \"        hard_count = sum(1 for item in landmark_report if \\\"Dif√≠cil\\\" in item['Dificuldade'])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"\\\\nüìä Distribui√ß√£o de Dificuldade:\\\")\\n\",\n",
    "    \"        print(f\\\"   F√°ceis: {easy_count} landmarks\\\")\\n\",\n",
    "    \"        print(f\\\"   Moderados: {moderate_count} landmarks\\\")\\n\",\n",
    "    \"        print(f\\\"   Dif√≠ceis: {hard_count} landmarks\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"‚ùå Nenhum dado v√°lido encontrado para gerar relat√≥rio\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Dados de resumo n√£o dispon√≠veis para gerar relat√≥rio\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Recomenda√ß√µes e Conclus√µes\\n\",\n",
    "    \"\\n\",\n",
    "    \"Com base na an√°lise realizada, fornecemos recomenda√ß√µes para melhorar o sistema.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== An√°lise Final e Recomenda√ß√µes ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not results_combined_df.empty:\\n\",\n",
    "    \"    # M√©tricas gerais finais\\n\",\n",
    "    \"    total_detections = len(results_combined_df)\\n\",\n",
    "    \"    successful_detections = len(results_combined_df.dropna(subset=['Error']))\\n\",\n",
    "    \"    overall_success_rate = (successful_detections / total_detections) * 100\\n\",\n",
    "    \"    overall_mean_error = results_combined_df['Error'].mean()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüìä M√©tricas Gerais do Sistema:\\\")\\n\",\n",
    "    \"    print(f\\\"   Total de tentativas de detec√ß√£o: {total_detections:,}\\\")\\n\",\n",
    "    \"    print(f\\\"   Detec√ß√µes bem-sucedidas: {successful_detections:,}\\\")\\n\",\n",
    "    \"    print(f\\\"   Taxa de sucesso geral: {overall_success_rate:.1f}%\\\")\\n\",\n",
    "    \"    print(f\\\"   Erro m√©dio geral: {overall_mean_error:.3f} mm\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Avalia√ß√£o da qualidade\\n\",\n",
    "    \"    print(f\\\"\\\\nüéØ Avalia√ß√£o da Qualidade:\\\")\\n\",\n",
    "    \"    if overall_success_rate >= 80:\\n\",\n",
    "    \"        quality_detection = \\\"Excelente ‚úÖ\\\"\\n\",\n",
    "    \"    elif overall_success_rate >= 60:\\n\",\n",
    "    \"        quality_detection = \\\"Boa ‚ö†Ô∏è\\\"\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        quality_detection = \\\"Precisa melhorar ‚ùå\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not np.isnan(overall_mean_error):\\n\",\n",
    "    \"        if overall_mean_error <= 3.0:\\n\",\n",
    "    \"            quality_precision = \\\"Excelente ‚úÖ\\\"\\n\",\n",
    "    \"        elif overall_mean_error <= 5.0:\\n\",\n",
    "    \"            quality_precision = \\\"Boa ‚ö†Ô∏è\\\"\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            quality_precision = \\\"Precisa melhorar ‚ùå\\\"\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        quality_precision = \\\"N√£o avali√°vel\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"   Taxa de detec√ß√£o: {quality_detection}\\\")\\n\",\n",
    "    \"    print(f\\\"   Precis√£o: {quality_precision}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Recomenda√ß√µes espec√≠ficas\\n\",\n",
    "    \"    print(f\\\"\\\\nüí° Recomenda√ß√µes para Melhoria:\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if overall_success_rate < 80:\\n\",\n",
    "    \"        print(f\\\"   üîß Taxa de detec√ß√£o baixa - considere:\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Refinar heur√≠sticas geom√©tricas\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Treinar modelos ML com mais dados\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Ajustar par√¢metros de confian√ßa\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not np.isnan(overall_mean_error) and overall_mean_error > 3.0:\\n\",\n",
    "    \"        print(f\\\"   üéØ Precis√£o baixa - considere:\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Melhorar qualidade da simplifica√ß√£o\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Adicionar features mais discriminativas no ML\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Validar orienta√ß√£o e escala das malhas\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Compara√ß√£o entre m√©todos\\n\",\n",
    "    \"    methods = results_combined_df['Method'].unique()\\n\",\n",
    "    \"    if len(methods) >= 2:\\n\",\n",
    "    \"        print(f\\\"\\\\n‚öñÔ∏è  Compara√ß√£o entre M√©todos:\\\")\\n\",\n",
    "    \"        for method in methods:\\n\",\n",
    "    \"            method_data = results_combined_df[results_combined_df['Method'] == method]\\n\",\n",
    "    \"            method_rate = method_data['Detected'].mean() * 100\\n\",\n",
    "    \"            method_error = method_data['Error'].mean()\\n\",\n",
    "    \"            print(f\\\"   {method}: {method_rate:.1f}% detec√ß√£o, {method_error:.3f}mm erro\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Recomendar melhor m√©todo\\n\",\n",
    "    \"        method_scores = {}\\n\",\n",
    "    \"        for method in methods:\\n\",\n",
    "    \"            method_data = results_combined_df[results_combined_df['Method'] == method]\\n\",\n",
    "    \"            rate = method_data['Detected'].mean() * 100\\n\",\n",
    "    \"            error = method_data['Error'].mean()\\n\",\n",
    "    \"            # Score combinado (rate ponderado por precis√£o)\\n\",\n",
    "    \"            if not np.isnan(error):\\n\",\n",
    "    \"                score = rate * (1 / (1 + error))\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                score = rate * 0.5  # Penalizar falta de dados\\n\",\n",
    "    \"            method_scores[method] = score\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        best_method = max(method_scores, key=method_scores.get)\\n\",\n",
    "    \"        print(f\\\"\\\\nüèÜ M√©todo Recomendado: {best_method}\\\")\\n\",\n",
    "    \"        print(f\\\"   Com base na combina√ß√£o de taxa de detec√ß√£o e precis√£o\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Dados insuficientes para an√°lise final\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n‚úÖ An√°lise completa conclu√≠da!\\\")\\n\",\n",
    "    \"print(f\\\"üìÅ Todos os resultados foram salvos em: {RESULTS_DIR}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclus√£o da An√°lise\\n\",\n",
    "    \"\\n\",\n",
    "    \"Esta an√°lise quantitativa demonstrou a capacidade de avalia√ß√£o sistem√°tica dos m√©todos de detec√ß√£o implementados.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Principais Contribui√ß√µes:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Framework de Avalia√ß√£o Robusto**: Sistema completo para calcular m√©tricas de precis√£o e robustez\\n\",\n",
    "    \"2. **An√°lise Comparativa**: Compara√ß√£o objetiva entre m√©todos geom√©trico e ML\\n\",\n",
    "    \"3. **Visualiza√ß√µes Informativas**: Gr√°ficos que facilitam interpreta√ß√£o dos resultados\\n\",\n",
    "    \"4. **Relat√≥rios Automatizados**: Documenta√ß√£o estruturada da performance por landmark\\n\",\n",
    "    \"5. **Recomenda√ß√µes Baseadas em Dados**: Sugest√µes concretas para melhorias\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Aspectos T√©cnicos Validados:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- ‚úÖ **M√©tricas Implementadas**: Erro de detec√ß√£o, MDE, taxa de detec√ß√£o\\n\",\n",
    "    \"- ‚úÖ **Processamento em Lote**: Avalia√ß√£o automatizada de datasets\\n\",\n",
    "    \"- ‚úÖ **An√°lise Estat√≠stica**: Compara√ß√µes significativas entre m√©todos\\n\",\n",
    "    \"- ‚úÖ **Visualiza√ß√£o Profissional**: Gr√°ficos publication-ready\\n\",\n",
    "    \"- ‚úÖ **Relat√≥rios Estruturados**: CSV e visualiza√ß√µes para documenta√ß√£o\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Para Trabalhos Futuros:\\n\",\n",
    "    \"\\n\",\n",
    "    \"Este framework de an√°lise est√° pronto para:\\n\",\n",
    "    \"- Avalia√ß√£o com dados reais (MUG500+, NMDID)\\n\",\n",
    "    \"- Compara√ß√£o com m√©todos da literatura\\n\",\n",
    "    \"- Otimiza√ß√£o de hiperpar√¢metros baseada em m√©tricas\\n\",\n",
    "    \"- Valida√ß√£o cruzada e testes estat√≠sticos rigorosos\\n\",\n",
    "    \"\\n\",\n",
    "    \"**O sistema de an√°lise est√° completo e funcional para avalia√ß√£o cient√≠fica rigorosa.**\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
